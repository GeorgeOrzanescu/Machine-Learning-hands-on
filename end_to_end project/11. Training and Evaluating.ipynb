{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training and Evaluating on the Training Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "housing = pd.read_csv(r\"C:\\Users\\georg\\Desktop\\Machine Learning\\notebooks_detailed\\datasets\\housing\\housing.csv\") \n",
    "\n",
    "housing[\"income_category\"] =pd.cut(housing[\"median_income\"],bins=[0,1.5,3.0,4.5,6.,np.inf],labels=[1,2,3,4,5])\n",
    "split_indices = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split_indices.split(housing,housing[\"income_category\"]): \n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):  ## we are dropping the new attribute\n",
    "    set_.drop(\"income_category\", axis=1, inplace=True)  \n",
    "    \n",
    "\n",
    "housing = strat_train_set.copy()  # make a copy of original data \n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() # seprate the target column\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1) # numerical attributes\n",
    "housing_cat = housing[[\"ocean_proximity\"]] # categorical attributes\n",
    "\n",
    "\n",
    "# this is a very condesated form , don't worry about it\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "            \n",
    "numerical_pipeline = Pipeline([    # The Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps.\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('attribs_adder', CombinedAttributesAdder()), \n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "num_attribs = list(housing_num)  # list of numerical columns \n",
    "cat_attribs = [\"ocean_proximity\"] #list of categorical columns \n",
    "\n",
    "full_pipeline = ColumnTransformer([ # The constructor requires a list of tuples, where each tuple contains a name, a transformer and a list of names (or indices) of columns that the transformer should be applied to\n",
    "(\"num\", numerical_pipeline, num_attribs), # name : whatever u want| transfomer : numerical_pipeline defined earlier|target:num_attribs\n",
    "(\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(housing_prepared,housing_labels)  #the algorithm \"learns\" from the training data "
   ]
  },
  {
   "source": [
    "### What we did is only create an instance of the linear regression model and calling the fit method on the training data so now the algorithm made some \"correlations\" that will use to make some predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[286600.0, 340600.0, 196900.0, 46300.0, 254500.0]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "original_data = housing.iloc[:5]\n",
    "original_target = housing_labels.iloc[:5]\n",
    "list(original_target)   # this are the original target values we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[210644.60459285564,\n",
       " 317768.80697210855,\n",
       " 210956.43331178208,\n",
       " 59218.98886849053,\n",
       " 189747.55849878516]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data_prepared = full_pipeline.transform(original_data)  #we make our transformations with the help of the pipeline we created \n",
    "predicted_target = linear_regression.predict(data_prepared) #we use predict method to make predictions on the newly prepared data\n",
    "# !! the linear regression model is already trained \n",
    "list(predicted_target)  "
   ]
  },
  {
   "source": [
    "## Let's check our accuracy with the mean_squared_error\n",
    "### First a view of the MSE : Mean squared error   and RMSE : root squared error\n",
    "\n",
    "**Mean Squared Error** (MSE) is a measure of how close a fitted line is to data points. For every data point, you take the distance vertically from the point to the corresponding y value on the curve fit (the error), and square the value.\n",
    "<br> **Root Mean** Squared Error (RMSE). It is just the square root of the mean square error. That is probably the most easily interpreted statistic, since it has the same units as the quantity plotted on the vertical axis.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "68628.19819848923"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = linear_regression.predict(housing_prepared)\n",
    "linear_RMSE = mean_squared_error(housing_labels,housing_predictions,squared=False) #squared parameter set to false to get RMSE\n",
    "linear_RMSE\n",
    "# so we have a prediction error of 68 628 $ which is pretty bad."
   ]
  },
  {
   "source": [
    "### This is an example of a model underfitting the training data. When this happens it can mean that the features do not provide enough information to make good predictions, or that the model is not powerful enough. As we saw in the previous chapter, the main ways to fix underfitting are to select a more powerful model, to feed the training algorithm with better features, or to reduce the constraints on the model.\n",
    "\n",
    "### Now will try to train a DecisionTreeRegressor capable of finding complex nonlinear relationships in the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regression = DecisionTreeRegressor()\n",
    "tree_regression.fit(housing_prepared,housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "housing_predictions_tree = tree_regression.predict(housing_prepared)\n",
    "tree_RMSE =mean_squared_error(housing_labels,housing_predictions_tree,squared=False)\n",
    "tree_RMSE"
   ]
  },
  {
   "source": [
    "### Wait, what!? No error at all? Could this model really be absolutely perfect? Of course, it is much more likely that the model has badly overfit the data. How can you be sure?\n",
    "### As we saw earlier, you don’t want to touch the test set until you are ready to launch a model you are confident about, so you need to use part of the training set for training, and part for model validation.\n",
    "\n",
    "### One way to evaluate the Decision Tree model would be to use the train_test_split function to split the training set into a smaller training set and a validation set, then train your models against the smaller training set and evaluate them against the validation set. It’s a bit of work, but nothing too difficult and it would work fairly well.\n",
    "\n",
    "### A much simpler alternative is to use Scikit-Learn K-fold cross-validation feature.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([70460.82710592, 65600.68791566, 68772.02881682, 69630.99338318,\n",
       "       71113.78937513, 72862.30236324, 71121.91068388, 70530.77393935,\n",
       "       77396.79371089, 70370.96792194])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_regression,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10) # cv is the parameter for number of folds default is 5\n",
    "tree_RMSE_scores = np.sqrt(-scores) #!! u have to negate the them because they are negative already in the scoring parameter more details below\n",
    "# https://stackoverflow.com/questions/21050110/sklearn-gridsearchcv-with-pipeline\n",
    "tree_RMSE_scores"
   ]
  },
  {
   "source": [
    "### now what cross_val_score is doing is it splits the training set into 10 distinct subsets called folds, then it trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores.\n",
    "\n",
    "### We can see that Decision Tree doesn't do any better then Linear Regression, actually worse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([66782.73843989, 66960.118071  , 70347.95244419, 74739.57052552,\n",
       "       68031.13388938, 71193.84183426, 64969.63056405, 68281.61137997,\n",
       "       71552.91566558, 67665.10082067])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# we will do the same for the linear model\n",
    "linear_scores = cross_val_score(linear_regression,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "linear_scores_RMSE = np.sqrt(-linear_scores)\n",
    "linear_scores_RMSE"
   ]
  },
  {
   "source": [
    "## Let's try one last model RandomForestRegressor - works by training many Decision Trees on random subsets of the features, then averaging out their predictions. Building a model on top of many other models is called Ensemble Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18603.515021376355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_regression = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "forest_regression.fit(housing_prepared,housing_labels)\n",
    "housing_predictions_forest = forest_regression.predict(housing_prepared)\n",
    "print(mean_squared_error(housing_labels,housing_predictions_forest,squared=False)) #score on the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([49519.80364233, 47461.9115823 , 50029.02762854, 52325.28068953,\n",
       "       49308.39426421, 53446.37892622, 48634.8036574 , 47585.73832311,\n",
       "       53490.10699751, 50021.5852922 ])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_regression,housing_prepared,housing_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_scores_RMSE = np.sqrt(-forest_scores)\n",
    "forest_scores_RMSE  #scores on the validation sets"
   ]
  },
  {
   "source": [
    "### RandomForestRegressor performs better then both previous models. However, note that the score on the training set is still much lower than on the validation sets, meaning that the model is still overfitting the training set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}