{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Prepare the Data for Machine Learning Algorithm\n",
    "### Instead of just doing this manually, you should write functions to do that, for several good reasons:\n",
    "        - This will allow you to reproduce these transformations easily on any dataset (e.g., the next time you get a fresh dataset).\n",
    "        - You will gradually build a library of transformation functions that you can reuse in future projects.\n",
    "        - You can use these functions in your live system to transform the new data before feeding it to your algorithms.\n",
    "        - This will make it possible for you to easily try various transformations and see which combination of transformations works best.\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "housing = pd.read_csv(r\"C:\\Users\\georg\\Desktop\\end_end\\datasets\\housing\\housing.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_category\"] =pd.cut(housing[\"median_income\"],bins=[0,1.5,3.0,4.5,6.,np.inf],labels=[1,2,3,4,5])\n",
    "split_indices = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split_indices.split(housing,housing[\"income_category\"]): \n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index] \n",
    "# standard by now"
   ]
  },
  {
   "source": [
    "### We will revert to a clean training set but : will separate the the attributes that will be used for predictions (PREDICTORS) and the labels or target values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\",axis=1) \n",
    "# drop() removes rows or column by specifying the name and the axis 0 = row   1 = column  \n",
    "# !! drop also creates a copy of the data so the original strat_train_test is not affected\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() "
   ]
  },
  {
   "source": [
    "### Data Cleaning - Missing features  ( values missing in some attribute instances)\n",
    "### 3 options:\n",
    "        - get rid of the corresponding instances\n",
    "        - get rid of the whole attribute\n",
    "        - set the values to some value ( mean,zero,median etc)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### total_bedrooms attribute has some missing values, so let’s fix this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "housing[\"total_bedrooms\"].isnull().sum()  \n",
    "# isnull() check for Nan/missing values \n",
    "# sum() just adds them togheter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "# # dropna() removes missing values     subset parameter takes in an array in our case column total_bedrooms and removes the row where we have no values\n",
    "# !!! this will not modify anything because dropna() function returns a new dataset without the NaN/missing values. So u have to assign it to a variable.\n",
    "housing[\"total_bedrooms\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "housing_with_dropna = housing.dropna(subset=[\"total_bedrooms\"]) \n",
    "housing_with_dropna[\"total_bedrooms\"].isnull().sum()\n",
    "# now it worked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "# same as dropna does not work without assign \n",
    "housing[\"total_bedrooms\"].isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "433.0\n"
     ]
    }
   ],
   "source": [
    "median = housing[\"total_bedrooms\"].median() # option 3   \n",
    "# # we calculate the median of the total values that are recorder in the column \n",
    "print(median)\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
   ]
  },
  {
   "source": [
    "#### Don’t forget to save the median value that you have computed. You will need it later to replace missing values in the test set when you want to evaluate your system, and also once the system goes live to replace missing values in new data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "housing[\"total_bedrooms\"].isnull().sum()\n",
    "# this worked because of the inplace parameter , which if set to True will modify the  original dataframe "
   ]
  },
  {
   "source": [
    "### Scikit-Learn provides a handy class to take care of missing values: SimpleImputer\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer  # importing transformer for completing missing values.\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")   # we have to create an instance , strategy is the method u want to apply to all attributes with missing values.\n",
    "\n",
    "# !!!!  this works only on numerical data so ocean_proximity will need to be separated from the data(for now)\n",
    "housing_numerical = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n",
       "        408.    ,    3.5409,    3.    ])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "imputer.fit(housing_numerical)\n",
    "imputer.statistics_   #  array of all the median values of each attribute"
   ]
  },
  {
   "source": [
    "### The imputer has simply computed the median of each attribute and stored the result in its statistics_ instance variable. Only the total_bedrooms attribute had missing values, but we cannot be sure that there won’t be any missing values in new data after the system goes live, so it is safer to apply the imputer to all the numerical attributes\n",
    "\n",
    "### what u really have to understand is that the imputer is a class not a function. And it works like a TRANSFORMER , it extracts values from some data ( it \"trains\" on that data) , after that it can TRANSFORM the data with what it learned.\n",
    "    - in our case it extracted the median values from housing_numerical dataframe \n",
    "    - and we will use it to apply does values to the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-121.89  ,   37.29  ,   38.    , ...,  339.    ,    2.7042,\n",
       "           2.    ],\n",
       "       [-121.93  ,   37.05  ,   14.    , ...,  113.    ,    6.4214,\n",
       "           5.    ],\n",
       "       [-117.2   ,   32.77  ,   31.    , ...,  462.    ,    2.8621,\n",
       "           2.    ],\n",
       "       ...,\n",
       "       [-116.4   ,   34.09  ,    9.    , ...,  765.    ,    3.2723,\n",
       "           3.    ],\n",
       "       [-118.01  ,   33.82  ,   31.    , ...,  356.    ,    4.0625,\n",
       "           3.    ],\n",
       "       [-122.45  ,   37.77  ,   52.    , ...,  639.    ,    3.575 ,\n",
       "           3.    ]])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "housing_numerical.median().values  \n",
    "# we can see that they are identical so it extracted them correctly\n",
    "X = imputer.transform(housing_numerical)  # we apply it using the transform() function\n",
    "X # is just a simple Numpy array with the transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to put it back in a Pandas dataframe we can \n",
    "housing_transformed = pd.DataFrame(X,columns=housing_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "income_category       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "housing_transformed.isnull().sum()"
   ]
  },
  {
   "source": [
    "# In the file number 7 will give more detailed explanations on how tranformers work. And we will try to understand the Scikit-Learn library design principles."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}